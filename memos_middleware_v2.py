"""
MemOS LangChain ä¸­é—´ä»¶ V2
==========================

ä½¿ç”¨ LangChain 1.0 çš„ wrap é£æ ¼ hooks + class ç±»å‹ä¸­é—´ä»¶ï¼Œ
å°† MemOS æ ‘å½¢è®°å¿†èƒ½åŠ›æ³¨å…¥åˆ° LangChain æ™ºèƒ½ä½“ä¸­ã€‚

V2 å˜æ›´è¯´æ˜:
- ä½¿ç”¨ MemosMemoryHelperV2ï¼ˆåŸºäº init_server + SingleCubeViewï¼‰
- é…ç½®æ›´ç®€æ´ï¼Œç”± init_server ç»Ÿä¸€ç®¡ç†
- API æ¥å£ä¿æŒä¸ V1 å…¼å®¹

åŠŸèƒ½ï¼š
1. before_agent: åœ¨ agent å¼€å§‹æ—¶æ£€ç´¢ç›¸å…³è®°å¿†ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
2. wrap_model_call: å°†æ£€ç´¢åˆ°çš„è®°å¿†æ³¨å…¥åˆ° system prompt
3. after_agent: åœ¨æ™ºèƒ½ä½“å®Œæˆåï¼Œå°†å¯¹è¯æ·»åŠ åˆ°è®°å¿†åº“

å‚è€ƒï¼š
- https://docs.langchain.com/oss/python/langchain/middleware/custom
- chatbot_with_memos_v3.py
"""

from datetime import datetime
from typing import Any, Callable, Optional

from langchain.agents.middleware import (
    AgentMiddleware,
    AgentState,
    ModelRequest,
    ModelResponse,
)
from langchain.messages import SystemMessage
from langgraph.runtime import Runtime

from memos_memory_helper_v2 import MemosMemoryHelperV2


# ==================== è®°å¿†ç³»ç»Ÿ Prompt æ¨¡æ¿ ====================
MEMORY_INJECTION_TEMPLATE = """
# é•¿æœŸè®°å¿†ä¸Šä¸‹æ–‡

ä»¥ä¸‹æ˜¯ä¸å½“å‰å¯¹è¯ç›¸å…³çš„å†å²è®°å¿†ä¿¡æ¯ï¼š

<memories>
{memories}
</memories>

è¯·ç»“åˆè¿™äº›è®°å¿†ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœè®°å¿†ä¸å½“å‰é—®é¢˜æ— å…³ï¼Œå¯ä»¥å¿½ç•¥ã€‚
ä¸è¦ç›´æ¥æåŠ"è®°å¿†"æˆ–"æ£€ç´¢"ç­‰ç³»ç»Ÿå†…éƒ¨æœ¯è¯­ã€‚
"""


class MemosMiddlewareV2(AgentMiddleware):
    """
    MemOS é•¿æœŸè®°å¿†ä¸­é—´ä»¶ V2
    
    ä½¿ç”¨ MemosMemoryHelperV2ï¼ˆåŸºäº SingleCubeView APIï¼‰å®ç°è®°å¿†åŠŸèƒ½ã€‚
    
    è®°å¿†æ£€ç´¢ç­–ç•¥ï¼š
    - before_agent: åœ¨ agent å¼€å§‹æ—¶æ£€ç´¢è®°å¿†ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼Œé¿å… ReAct å¾ªç¯ä¸­é‡å¤æ£€ç´¢ï¼‰
    - wrap_model_call: å°†å·²æ£€ç´¢çš„è®°å¿†æ³¨å…¥åˆ°æ¯æ¬¡æ¨¡å‹è°ƒç”¨çš„ system prompt
    - after_agent: åœ¨æ™ºèƒ½ä½“å®Œæˆåï¼Œå°†å¯¹è¯æ·»åŠ åˆ°è®°å¿†åº“
    """
    
    def __init__(
        self,
        user_id: str = "langchain_agent_user",
        cube_id: str = None,
        top_k: int = 5,
        auto_memorize: bool = True,
        verbose: bool = True,
    ):
        """
        åˆå§‹åŒ– MemOS ä¸­é—´ä»¶ V2
        
        Args:
            user_id: ç”¨æˆ·IDï¼Œç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„è®°å¿†
            cube_id: MemCube IDï¼Œç”¨äºåŒºåˆ†ä¸åŒçš„è®°å¿†ç©ºé—´
            top_k: è®°å¿†æ£€ç´¢æ—¶è¿”å›çš„æœ€å¤§æ•°é‡
            auto_memorize: æ˜¯å¦è‡ªåŠ¨å°†å¯¹è¯æ·»åŠ åˆ°è®°å¿†
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
        """
        self.user_id = user_id
        self.cube_id = cube_id
        self.top_k = top_k
        self.auto_memorize = auto_memorize
        self.verbose = verbose
        
        # åˆå§‹åŒ– MemOS è®°å¿†åŠ©æ‰‹ V2
        self.memory_helper = MemosMemoryHelperV2(
            user_id=user_id,
            cube_id=cube_id,
            top_k=top_k
        )
        
        # å½“å‰ä»»åŠ¡çš„è®°å¿†ç¼“å­˜ï¼ˆæ¯æ¬¡ agent è°ƒç”¨æ—¶é‡ç½®ï¼‰
        self._current_memories: list[str] = []
        self._current_query: Optional[str] = None
    
    def _log(self, message: str):
        """æ‰“å°æ—¥å¿—"""
        if self.verbose:
            print(f"ğŸ§  [MemosMiddlewareV2] {message}")
    
    def before_agent(
        self,
        state: AgentState,
        runtime: Runtime,
    ) -> dict[str, Any] | None:
        """
        Node é£æ ¼ hook: åœ¨ agent å¼€å§‹æ—¶æ‰§è¡Œï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
        
        åœ¨è¿™é‡Œæ£€ç´¢è®°å¿†ï¼Œé¿å…åœ¨ ReAct å¾ªç¯ä¸­é‡å¤æ£€ç´¢
        
        Args:
            state: æ™ºèƒ½ä½“çŠ¶æ€
            runtime: è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
            
        Returns:
            å¯é€‰çš„çŠ¶æ€æ›´æ–°
        """
        
        # é‡ç½®ç¼“å­˜
        self._current_memories = []
        self._current_query = None
        
        # ä» state ä¸­æå–ç”¨æˆ·çš„æœ€æ–°æ¶ˆæ¯
        messages = state.get("messages", [])
        user_query = None
        
        # ä»åå¾€å‰æŸ¥æ‰¾æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
        for msg in reversed(messages):
            msg_type = getattr(msg, 'type', None) or msg.__class__.__name__.lower()
            if msg_type in ('human', 'humanmessage'):
                user_query = msg.content
                break
        
        if user_query:
            self._current_query = user_query
            self._log(f"æ£€æµ‹åˆ°ç”¨æˆ·æŸ¥è¯¢: {user_query[:50]}...")
            
            # æ£€ç´¢ç›¸å…³è®°å¿†ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
            self._current_memories = self.memory_helper.search_memories(user_query)
            
            if self._current_memories:
                self._log(f"æ£€ç´¢åˆ° {len(self._current_memories)} æ¡ç›¸å…³è®°å¿†")
            else:
                self._log("æœªæ£€ç´¢åˆ°ç›¸å…³è®°å¿†")
        
        return None
    
    def wrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        """
        Wrap é£æ ¼ hook: åœ¨æ¯æ¬¡æ¨¡å‹è°ƒç”¨æ—¶æ‰§è¡Œ
        
        å°† before_agent ä¸­æ£€ç´¢åˆ°çš„è®°å¿†æ³¨å…¥åˆ° system prompt
        ï¼ˆä¸å†é‡å¤æ£€ç´¢ï¼Œåªæ³¨å…¥å·²ç¼“å­˜çš„è®°å¿†ï¼‰
        
        Args:
            request: æ¨¡å‹è¯·æ±‚å¯¹è±¡
            handler: åŸå§‹æ¨¡å‹è°ƒç”¨å¤„ç†å™¨
            
        Returns:
            æ¨¡å‹å“åº”
        """
        # å¦‚æœæœ‰ç¼“å­˜çš„è®°å¿†ï¼Œæ³¨å…¥åˆ° system prompt
        if self._current_memories:
            request = self._inject_memories_to_prompt(request, self._current_memories)
        
        # è°ƒç”¨åŸå§‹æ¨¡å‹å¹¶è¿”å›å“åº”
        return handler(request)
    
    def after_agent(
        self,
        state: AgentState,
        runtime: Runtime,
    ) -> dict[str, Any] | None:
        """
        Node é£æ ¼ hook: åœ¨æ™ºèƒ½ä½“å®Œæˆåæ‰§è¡Œ
        
        å°†æœ¬è½®å¯¹è¯æ·»åŠ åˆ°è®°å¿†åº“ï¼ŒåŒ…æ‹¬ï¼š
        - user: ç”¨æˆ·æ¶ˆæ¯
        - assistant: åŠ©æ‰‹å›å¤ï¼ˆå¯èƒ½åŒ…å« tool_callsï¼‰
        - tool: å·¥å…·è¿”å›ç»“æœ
        
        Args:
            state: æ™ºèƒ½ä½“çŠ¶æ€
            runtime: è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
            
        Returns:
            å¯é€‰çš„çŠ¶æ€æ›´æ–°
        """
        if not self.auto_memorize:
            return None
        
        # ä» state çš„ messages ä¸­æå–æœ¬è½®å®Œæ•´å¯¹è¯
        messages = state.get("messages", [])
        conversation = self._extract_full_conversation(messages)
        
        if conversation:
            self._log(f"å°†å¯¹è¯æ·»åŠ åˆ°è®°å¿†åº“ ({len(conversation)} æ¡æ¶ˆæ¯)")
            self.memory_helper.add_full_conversation(conversation)
        
        return None
    
    def _extract_full_conversation(self, messages: list) -> list[dict[str, Any]]:
        """
        ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–æœ¬è½®å®Œæ•´å¯¹è¯
        
        åŒ…æ‹¬ userã€assistantï¼ˆå¸¦ tool_callsï¼‰ã€tool æ¶ˆæ¯
        
        Args:
            messages: LangChain æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        """
        # æ‰¾åˆ°æœ€åä¸€ä¸ª user æ¶ˆæ¯çš„ç´¢å¼•
        user_index = None
        for i in range(len(messages) - 1, -1, -1):
            msg = messages[i]
            msg_type = getattr(msg, 'type', None) or msg.__class__.__name__.lower()
            if msg_type in ('human', 'humanmessage'):
                user_index = i
                break
        
        if user_index is None:
            return []
        
        # ä» user æ¶ˆæ¯å¼€å§‹ï¼Œæå–åç»­æ‰€æœ‰æ¶ˆæ¯
        conversation = []
        for msg in messages[user_index:]:
            msg_type = getattr(msg, 'type', None) or msg.__class__.__name__.lower()
            
            if msg_type in ('human', 'humanmessage'):
                # ç”¨æˆ·æ¶ˆæ¯
                conversation.append({
                    "role": "user",
                    "content": msg.content
                })
                
            elif msg_type in ('ai', 'aimessage'):
                # åŠ©æ‰‹æ¶ˆæ¯
                assistant_msg = {
                    "role": "assistant",
                    "content": msg.content or ""
                }
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ tool_calls
                tool_calls = getattr(msg, 'tool_calls', None)
                if tool_calls:
                    # è½¬æ¢ä¸º OpenAI æ ¼å¼çš„ tool_calls
                    formatted_tool_calls = []
                    for tc in tool_calls:
                        if isinstance(tc, dict):
                            formatted_tool_calls.append({
                                "id": tc.get("id", ""),
                                "type": "function",
                                "function": {
                                    "name": tc.get("name", ""),
                                    "arguments": tc.get("args", "{}")
                                    if isinstance(tc.get("args"), str)
                                    else str(tc.get("args", "{}"))
                                }
                            })
                        else:
                            # å¯èƒ½æ˜¯å¯¹è±¡å½¢å¼
                            formatted_tool_calls.append({
                                "id": getattr(tc, 'id', ''),
                                "type": "function",
                                "function": {
                                    "name": getattr(tc, 'name', ''),
                                    "arguments": str(getattr(tc, 'args', '{}'))
                                }
                            })
                    
                    if formatted_tool_calls:
                        assistant_msg["tool_calls"] = formatted_tool_calls
                
                conversation.append(assistant_msg)
                
            elif msg_type in ('tool', 'toolmessage'):
                # å·¥å…·è¿”å›æ¶ˆæ¯
                tool_call_id = getattr(msg, 'tool_call_id', None) or getattr(msg, 'id', '')
                tool_name = getattr(msg, 'name', 'unknown_tool')
                
                # å¤„ç† content - å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¤æ‚å¯¹è±¡
                content = msg.content
                if not isinstance(content, str):
                    import json
                    try:
                        content = json.dumps(content, ensure_ascii=False, default=str)
                    except:
                        content = str(content)
                
                # æˆªæ–­è¿‡é•¿çš„å·¥å…·ç»“æœï¼ˆé¿å…å­˜å‚¨è¿‡å¤šæ•°æ®ï¼‰
                if len(content) > 2000:
                    content = content[:2000] + "... [truncated]"
                
                conversation.append({
                    "role": "tool",
                    "tool_call_id": tool_call_id,
                    "name": tool_name,
                    "content": content
                })
        
        return conversation
    
    def _inject_memories_to_prompt(
        self,
        request: ModelRequest,
        memories: list[str],
    ) -> ModelRequest:
        """
        å°†æ£€ç´¢åˆ°çš„è®°å¿†æ³¨å…¥åˆ° system prompt
        
        Args:
            request: åŸå§‹è¯·æ±‚
            memories: è®°å¿†åˆ—è¡¨
            
        Returns:
            ä¿®æ”¹åçš„è¯·æ±‚
        """
        # æ ¼å¼åŒ–è®°å¿†
        formatted_memories = self.memory_helper.format_memories_for_prompt(memories)
        
        # æ„å»ºè®°å¿†æ³¨å…¥æ–‡æœ¬
        memory_context = MEMORY_INJECTION_TEMPLATE.format(memories=formatted_memories)
        
        # è·å–å½“å‰çš„ system message content blocks
        current_blocks = list(request.system_message.content_blocks)
        
        # æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡åˆ° system message
        new_content = current_blocks + [
            {"type": "text", "text": memory_context}
        ]
        
        new_system_message = SystemMessage(content=new_content)
        
        return request.override(system_message=new_system_message)
    
    # ==================== ä¾¿æ·æ–¹æ³• ====================
    
    def force_memorize(self):
        """å¼ºåˆ¶å°†æ‰€æœ‰æœªè®°å¿†çš„å¯¹è¯æ·»åŠ åˆ°è®°å¿†åº“"""
        self.memory_helper.force_memorize()
    
    def clear_memories(self):
        """æ¸…ç©ºæ‰€æœ‰è®°å¿†"""
        self.memory_helper.clear_memories()
    
    def get_memory_count(self) -> int:
        """è·å–è®°å¿†æ•°é‡"""
        return self.memory_helper.get_memory_count()
    
    def show_memories(self, limit: int = 20):
        """æ˜¾ç¤ºè®°å¿†"""
        memories = self.memory_helper.get_all_memories(limit=limit)
        print(f"\nğŸ“š å½“å‰å…±æœ‰ {len(memories)} æ¡è®°å¿†:")
        for i, mem in enumerate(memories, 1):
            print(f"  [{i}] [{mem['type']}] {mem['memory'][:80]}...")
    
    def close(self):
        """å…³é—­ä¸­é—´ä»¶ï¼Œé‡Šæ”¾ MemOS èµ„æº"""
        self.memory_helper.close()


# ==================== ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºå¸¦è®°å¿†çš„ä¸­é—´ä»¶ ====================

def create_memos_middleware_v2(
    user_id: str = "langchain_agent_user",
    cube_id: str = None,
    top_k: int = 5,
    auto_memorize: bool = True,
    verbose: bool = True,
) -> MemosMiddlewareV2:
    """
    åˆ›å»º MemOS è®°å¿†ä¸­é—´ä»¶ V2 çš„ä¾¿æ·å‡½æ•°
    
    Args:
        user_id: ç”¨æˆ·ID
        cube_id: MemCube ID
        top_k: æ£€ç´¢æ•°é‡
        auto_memorize: æ˜¯å¦è‡ªåŠ¨è®°å¿†
        verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
        
    Returns:
        MemosMiddlewareV2 å®ä¾‹
    """
    return MemosMiddlewareV2(
        user_id=user_id,
        cube_id=cube_id,
        top_k=top_k,
        auto_memorize=auto_memorize,
        verbose=verbose,
    )


if __name__ == "__main__":
    # æµ‹è¯•ä¸­é—´ä»¶åˆ›å»º
    middleware = create_memos_middleware_v2(user_id="test_middleware_user_v2")
    print(f"ä¸­é—´ä»¶ V2 åˆ›å»ºæˆåŠŸï¼Œå½“å‰è®°å¿†æ•°é‡: {middleware.get_memory_count()}")
    
    # å…³é—­èµ„æº
    middleware.close()
